{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PRE-INSTALLATION OF ALL THE USED PACKAGES AND LIBRARIES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: pip in /Users/mimine/Library/Python/3.9/lib/python/site-packages (24.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: SPARQLWrapper in /Users/mimine/Library/Python/3.9/lib/python/site-packages (2.0.0)\n",
      "Requirement already satisfied: pandas in /Users/mimine/Library/Python/3.9/lib/python/site-packages (2.2.1)\n",
      "Requirement already satisfied: matplotlib in /Users/mimine/Library/Python/3.9/lib/python/site-packages (3.8.3)\n",
      "Requirement already satisfied: numpy in /Users/mimine/Library/Python/3.9/lib/python/site-packages (1.26.4)\n",
      "Requirement already satisfied: Pillow in /Users/mimine/Library/Python/3.9/lib/python/site-packages (10.2.0)\n",
      "Requirement already satisfied: requests in /Users/mimine/Library/Python/3.9/lib/python/site-packages (2.31.0)\n",
      "Requirement already satisfied: scikit-learn in /Users/mimine/Library/Python/3.9/lib/python/site-packages (1.4.1.post1)\n",
      "Requirement already satisfied: rdflib>=6.1.1 in /Users/mimine/Library/Python/3.9/lib/python/site-packages (from SPARQLWrapper) (7.0.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /Users/mimine/Library/Python/3.9/lib/python/site-packages (from pandas) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /Users/mimine/Library/Python/3.9/lib/python/site-packages (from pandas) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /Users/mimine/Library/Python/3.9/lib/python/site-packages (from pandas) (2024.1)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /Users/mimine/Library/Python/3.9/lib/python/site-packages (from matplotlib) (1.2.0)\n",
      "Requirement already satisfied: cycler>=0.10 in /Users/mimine/Library/Python/3.9/lib/python/site-packages (from matplotlib) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /Users/mimine/Library/Python/3.9/lib/python/site-packages (from matplotlib) (4.49.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /Users/mimine/Library/Python/3.9/lib/python/site-packages (from matplotlib) (1.4.5)\n",
      "Requirement already satisfied: packaging>=20.0 in /Users/mimine/Library/Python/3.9/lib/python/site-packages (from matplotlib) (23.2)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /Users/mimine/Library/Python/3.9/lib/python/site-packages (from matplotlib) (3.1.1)\n",
      "Requirement already satisfied: importlib-resources>=3.2.0 in /Users/mimine/Library/Python/3.9/lib/python/site-packages (from matplotlib) (6.1.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/mimine/Library/Python/3.9/lib/python/site-packages (from requests) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/mimine/Library/Python/3.9/lib/python/site-packages (from requests) (3.6)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/mimine/Library/Python/3.9/lib/python/site-packages (from requests) (2.2.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/mimine/Library/Python/3.9/lib/python/site-packages (from requests) (2024.2.2)\n",
      "Requirement already satisfied: scipy>=1.6.0 in /Users/mimine/Library/Python/3.9/lib/python/site-packages (from scikit-learn) (1.12.0)\n",
      "Requirement already satisfied: joblib>=1.2.0 in /Users/mimine/Library/Python/3.9/lib/python/site-packages (from scikit-learn) (1.3.2)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /Users/mimine/Library/Python/3.9/lib/python/site-packages (from scikit-learn) (3.3.0)\n",
      "Requirement already satisfied: zipp>=3.1.0 in /Users/mimine/Library/Python/3.9/lib/python/site-packages (from importlib-resources>=3.2.0->matplotlib) (3.17.0)\n",
      "Requirement already satisfied: six>=1.5 in /Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/site-packages (from python-dateutil>=2.8.2->pandas) (1.15.0)\n",
      "Requirement already satisfied: isodate<0.7.0,>=0.6.0 in /Users/mimine/Library/Python/3.9/lib/python/site-packages (from rdflib>=6.1.1->SPARQLWrapper) (0.6.1)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install --upgrade pip\n",
    "%pip install SPARQLWrapper pandas matplotlib numpy Pillow requests scikit-learn \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following Python script queries Wikidata for information about cars, downloads their images, and extracts metadata, including image size, format, orientation, creation date, and EXIF data. The script handles potential errors during image processing and saves the metadata for the downloaded images in a JSON file. The goal is to create a comprehensive dataset of car images with associated metadata for further analysis or use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloaded: Kharkovchanka_image_1.jpg\n",
      "Downloaded: Ferrari250GTBoanoEllenacar_image_2.jpg\n",
      "Downloaded: Fiat770_image_3.jpg\n",
      "Downloaded: CampagnaTRex_image_4.jpg\n",
      "Downloaded: CG1200S_image_5.jpg\n",
      "Downloaded: VAZ2104_image_6.jpg\n",
      "Downloaded: Fiat1500Lcar_image_7.jpg\n",
      "Downloaded: Fiat500Giardiniera_image_8.jpg\n",
      "Downloaded: Ferrari250P_image_9.jpg\n",
      "Downloaded: GeelyKingKong_image_10.jpg\n",
      "All metadata saved to: *json*/metadata.json\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import os\n",
    "from SPARQLWrapper import SPARQLWrapper, JSON\n",
    "from PIL import Image\n",
    "import json\n",
    "import urllib\n",
    "import time\n",
    "import re\n",
    "from PIL.ExifTags import TAGS\n",
    "\n",
    "endpoint_url = \"https://query.wikidata.org/sparql\"\n",
    "\n",
    "query = \"\"\"SELECT DISTINCT ?car ?carLabel ?image {\n",
    "  ?car wdt:P31 wd:Q1420;\n",
    "       wdt:P18 ?image.\n",
    " SERVICE wikibase:label { bd:serviceParam wikibase:language \"en\". }\n",
    "}\n",
    "LIMIT 10\"\"\"\n",
    "\n",
    "def get_results(endpoint_url, query):\n",
    "    user_agent = \"me/1.0 (me@email.com)\"\n",
    "    sparql = SPARQLWrapper(endpoint_url, agent=user_agent)\n",
    "    sparql.setQuery(query)\n",
    "    sparql.setReturnFormat(JSON)\n",
    "    return sparql.query().convert()\n",
    "\n",
    "def download_image_metadata(images_folder, data, limit=10):\n",
    "    # Ensure the images folder exists\n",
    "    if not os.path.exists(images_folder):\n",
    "        os.makedirs(images_folder)\n",
    "\n",
    "    # List to accumulate metadata for all images\n",
    "    all_metadata = []\n",
    "\n",
    "    for i, result in enumerate(data[\"results\"][\"bindings\"]):\n",
    "        if i >= limit:\n",
    "            break\n",
    "\n",
    "        car_label = result.get(\"carLabel\", {}).get(\"value\", f\"UnknownCar_{i + 1}\")\n",
    "        # Remove special characters from the car label for file path\n",
    "        car_label_cleaned = re.sub(r'\\W+', '', car_label)\n",
    "        image_url = result.get(\"image\", {}).get(\"value\", \"\")\n",
    "\n",
    "        image_name = f\"{car_label_cleaned}_image_{i + 1}.jpg\"\n",
    "        image_path = os.path.join(images_folder, image_name)\n",
    "\n",
    "        try:\n",
    "            # Download the image from Wikidata\n",
    "            urllib.request.urlretrieve(image_url, image_path)\n",
    "\n",
    "            print(f\"Downloaded: {image_name}\")\n",
    "\n",
    "            # Get metadata and accumulate in the list\n",
    "            metadata = get_metadata(image_path)\n",
    "            all_metadata.append(metadata)\n",
    "\n",
    "            # Introduce a delay between requests to comply with rate limits\n",
    "            time.sleep(1)\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing image {image_name}: {e}\")\n",
    "\n",
    "    # Ensure the json folder exists\n",
    "    if not os.path.exists(json_folder):\n",
    "        os.makedirs(json_folder)\n",
    "        \n",
    "    # Save all metadata to a single JSON file\n",
    "    json_file_path = os.path.join(json_folder,\"metadata.json\")\n",
    "    with open(json_file_path, \"w\") as json_file:\n",
    "        json.dump(all_metadata, json_file, indent=4)\n",
    "\n",
    "    print(f\"All metadata saved to: {json_file_path}\")\n",
    "\n",
    "\n",
    "def get_exif_metadata(exif_data):\n",
    "    if exif_data:\n",
    "        exif_metadata = {}\n",
    "        for tag, value in exif_data.items():\n",
    "            tag_name = TAGS.get(tag, tag)\n",
    "            # Exclude problematic values\n",
    "            if isinstance(value, bytes):\n",
    "                continue\n",
    "            # Convert non-serializable types to string\n",
    "            if isinstance(value, (str, int, float)):\n",
    "                exif_metadata[tag_name] = value\n",
    "            else:\n",
    "                exif_metadata[tag_name] = str(value)\n",
    "        return exif_metadata\n",
    "    return {}\n",
    "\n",
    "def get_metadata(image_path):\n",
    "    with Image.open(image_path) as img:\n",
    "        exif_data = img._getexif()  # Get EXIF data\n",
    "        metadata = {\n",
    "            \"image_name\": os.path.basename(image_path),\n",
    "            \"image_size\": img.size,\n",
    "            \"image_format\": img.format,\n",
    "            \"image_orientation\": get_image_orientation(exif_data),\n",
    "            \"creation_date\": get_creation_date(exif_data),\n",
    "            \"exif_metadata\": get_exif_metadata(exif_data),\n",
    "        }\n",
    "        return metadata\n",
    "\n",
    "def get_image_orientation(exif_data):\n",
    "    if exif_data:\n",
    "        orientation = exif_data.get(274)  # 274 corresponds to the 'Orientation' tag\n",
    "        if orientation is not None:\n",
    "            return orientation\n",
    "    return \"Unknown\"\n",
    "\n",
    "def get_creation_date(exif_data):\n",
    "    if exif_data:\n",
    "        date_time_original = exif_data.get(36867)  # 36867 corresponds to 'DateTimeOriginal' tag\n",
    "        if date_time_original is not None:\n",
    "            return date_time_original\n",
    "    return \"Unknown\"\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Specify the folder paths\n",
    "    images_folder = \"*images*\"\n",
    "    json_folder = \"*json*\"\n",
    "\n",
    "    # Get results from Wikidata\n",
    "    results = get_results(endpoint_url, query)\n",
    "\n",
    "    # Download images and save metadata\n",
    "    download_image_metadata(images_folder, results, limit=10)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we are going to use the following script to determine the 3 predominant colors in each image by using Random Forest Classifier. The script will also create a new dataset with the image metadata and the 3 predominant colors for each image.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                    Image  \\\n",
      "0               Kharkovchanka_image_1.jpg   \n",
      "1              GeelyKingKong_image_10.jpg   \n",
      "2                     CG1200S_image_5.jpg   \n",
      "3                     Fiat770_image_3.jpg   \n",
      "4          Fiat500Giardiniera_image_8.jpg   \n",
      "5                     VAZ2104_image_6.jpg   \n",
      "6                Fiat1500Lcar_image_7.jpg   \n",
      "7                CampagnaTRex_image_4.jpg   \n",
      "8  Ferrari250GTBoanoEllenacar_image_2.jpg   \n",
      "9                 Ferrari250P_image_9.jpg   \n",
      "\n",
      "                                 Predominant Colors  \n",
      "0  [[102, 107, 125], [186, 187, 190], [64, 52, 42]]  \n",
      "1  [[138, 134, 122], [199, 199, 200], [57, 58, 47]]  \n",
      "2   [[131, 118, 97], [52, 48, 33], [137, 210, 229]]  \n",
      "3   [[67, 47, 46], [180, 178, 174], [122, 112, 88]]  \n",
      "4  [[26, 47, 45], [198, 219, 237], [114, 138, 115]]  \n",
      "5   [[56, 56, 57], [146, 141, 145], [96, 106, 112]]  \n",
      "6    [[80, 103, 75], [149, 171, 201], [29, 43, 31]]  \n",
      "7   [[116, 121, 99], [196, 209, 141], [47, 46, 28]]  \n",
      "8   [[139, 104, 99], [63, 38, 37], [213, 212, 212]]  \n",
      "9  [[108, 108, 101], [158, 157, 152], [19, 20, 15]]  \n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "from PIL import Image\n",
    "import pandas as pd\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "def extract_colors(image_path, num_colors=3):\n",
    "    image = Image.open(image_path)\n",
    "    # Resize the image to a small size for faster processing\n",
    "    resized_image = image.resize((50, 50))\n",
    "    pixels = list(resized_image.getdata())\n",
    "\n",
    "    # Use K-Means clustering to find the predominant colors\n",
    "    kmeans = KMeans(n_clusters=num_colors)\n",
    "    kmeans.fit(pixels)\n",
    "    predominant_colors = kmeans.cluster_centers_.astype(int)\n",
    "\n",
    "    return predominant_colors.tolist()\n",
    "\n",
    "def process_images(folder_path, num_colors=3):\n",
    "    data = []\n",
    "\n",
    "    for filename in os.listdir(folder_path):\n",
    "        if filename.endswith(('.jpg', '.jpeg', '.png')):\n",
    "            image_path = os.path.join(folder_path, filename)\n",
    "            colors = extract_colors(image_path, num_colors)\n",
    "            data.append({'Image': filename, 'Predominant Colors': colors})\n",
    "\n",
    "    return pd.DataFrame(data)\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    folder_path = \"*images*\"  # Replace with the actual path to your image folder\n",
    "    output_json_path = \"*json*/predominant_colors.json\"  # Replace with the actual path for the output JSON file\n",
    "\n",
    "    # Process images and create DataFrame\n",
    "    df = process_images(folder_path)\n",
    "\n",
    "    # Save the DataFrame to a JSON file\n",
    "    df.to_json(output_json_path, orient='records')\n",
    "    \n",
    "    data = json.load(open(output_json_path))\n",
    "    dataframe = pd.json_normalize(data)\n",
    "   \n",
    "    print(dataframe)\n",
    "    \n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After that, we will ask the user to select some images and add tags. For every user, we are now ready to build a user-preference profile, based on this selection. We may collect the following information manually, but the objective of this task is to obtain them using the selected images in an automated manner.\n",
    "The following information will be collected:\n",
    "    - Favorite colors\n",
    "    - Favorite image orientation\n",
    "    - Favorite image sizes (thumbnail images, large images, medium-size images, etc.)\n",
    "    - Favorite tags\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "# Prompt the user to input their favorite colors\n",
    "favorite_colors = input(\"Enter your favorite colors (separated by commas): \").split(\",\")\n",
    "\n",
    "# Prompt the user to input their favorite image orientation\n",
    "favorite_orientation = input(\"Enter your favorite image orientation: (thumbnail images, large images, medium-size images, etc.)\")\n",
    "\n",
    "# Prompt the user to input their favorite image sizes\n",
    "favorite_sizes = input(\"Enter your favorite image sizes (separated by commas): \").split(\",\")\n",
    "\n",
    "# Prompt the user to input their favorite tags\n",
    "favorite_tags = input(\"Enter your favorite tags (separated by commas): \").split(\",\")\n",
    "\n",
    "# Print the images one by one and ask the user to choose if he likes the image or not\n",
    "# Specify the folder path where the images are located\n",
    "folder_path = \"*images*\"\n",
    "\n",
    "# Get the list of image files in the folder\n",
    "image_files = [filename for filename in os.listdir(folder_path) if filename.endswith(('.jpg', '.jpeg', '.png'))]\n",
    "\n",
    "# Iterate over the image files\n",
    "for image_file in image_files:\n",
    "    # Construct the full path of the image\n",
    "    image_path = os.path.join(folder_path, image_file)\n",
    "    \n",
    "    # Display the image\n",
    "    display(Image.open(image_path))\n",
    "    \n",
    "    # Prompt the user to choose if they like the image or not\n",
    "    user_choice = input(f\"Do you like the image '{image_file}'? (yes/no): \")\n",
    "    \n",
    "    liked_images = []\n",
    "    \n",
    "    # Process the user's choice\n",
    "    if user_choice.lower() == \"yes\":\n",
    "        # we will add the image to the user's preference profile\n",
    "        liked_images.append(image_file)\n",
    "        \n",
    "        pass\n",
    "    elif user_choice.lower() == \"no\":\n",
    "        pass\n",
    "    else:\n",
    "        print(\"Invalid choice. Please enter 'yes' or 'no'.\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Build the user-preference profile\n",
    "user_preference_profile = {\n",
    "    \"favorite_colors\": favorite_colors,\n",
    "    \"favorite_orientation\": favorite_orientation,\n",
    "    \"favorite_sizes\": favorite_sizes,\n",
    "    \"favorite_tags\": favorite_tags,\n",
    "    \"liked_images\": liked_images\n",
    "}\n",
    "\n",
    "# Specify the file path for the user-preference profile JSON file\n",
    "json_file_path = \"./*json*/user-preference_profile.json\"\n",
    "\n",
    "# Save the user-preference profile as a JSON file\n",
    "with open(json_file_path, \"w\") as json_file:\n",
    "    json.dump(user_preference_profile, json_file)\n",
    "\n",
    "print(f\"User-preference profile saved to: {json_file_path}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'convert_color_to_rgb' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [8], line 29\u001b[0m\n\u001b[1;32m     26\u001b[0m     existing_metadata \u001b[38;5;241m=\u001b[39m json\u001b[38;5;241m.\u001b[39mload(json_file)\n\u001b[1;32m     28\u001b[0m \u001b[38;5;66;03m# Filter car images based on user's preferences\u001b[39;00m\n\u001b[0;32m---> 29\u001b[0m filtered_images \u001b[38;5;241m=\u001b[39m \u001b[43mfilter_car_images\u001b[49m\u001b[43m(\u001b[49m\u001b[43muser_preference_profile\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexisting_metadata\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     31\u001b[0m \u001b[38;5;66;03m# Print the filtered images\u001b[39;00m\n\u001b[1;32m     32\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m image \u001b[38;5;129;01min\u001b[39;00m filtered_images:\n",
      "Cell \u001b[0;32mIn [8], line 9\u001b[0m, in \u001b[0;36mfilter_car_images\u001b[0;34m(user_preference_profile, car_images)\u001b[0m\n\u001b[1;32m      6\u001b[0m filtered_images \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m      8\u001b[0m \u001b[38;5;66;03m# Convert favorite colors to RGB format\u001b[39;00m\n\u001b[0;32m----> 9\u001b[0m favorite_colors \u001b[38;5;241m=\u001b[39m [convert_color_to_rgb(color) \u001b[38;5;28;01mfor\u001b[39;00m color \u001b[38;5;129;01min\u001b[39;00m user_preference_profile[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfavorite_colors\u001b[39m\u001b[38;5;124m\"\u001b[39m]]\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m image \u001b[38;5;129;01min\u001b[39;00m car_images:\n\u001b[1;32m     12\u001b[0m     \u001b[38;5;66;03m# Check if the predominant colors match the user's favorite colors\u001b[39;00m\n\u001b[1;32m     13\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mall\u001b[39m(color \u001b[38;5;129;01min\u001b[39;00m favorite_colors \u001b[38;5;28;01mfor\u001b[39;00m color \u001b[38;5;129;01min\u001b[39;00m image[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpredominant_colors\u001b[39m\u001b[38;5;124m\"\u001b[39m]):\n\u001b[1;32m     14\u001b[0m         \u001b[38;5;66;03m# Check if the image orientation matches the user's favorite image orientation\u001b[39;00m\n",
      "Cell \u001b[0;32mIn [8], line 9\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m      6\u001b[0m filtered_images \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m      8\u001b[0m \u001b[38;5;66;03m# Convert favorite colors to RGB format\u001b[39;00m\n\u001b[0;32m----> 9\u001b[0m favorite_colors \u001b[38;5;241m=\u001b[39m [\u001b[43mconvert_color_to_rgb\u001b[49m(color) \u001b[38;5;28;01mfor\u001b[39;00m color \u001b[38;5;129;01min\u001b[39;00m user_preference_profile[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfavorite_colors\u001b[39m\u001b[38;5;124m\"\u001b[39m]]\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m image \u001b[38;5;129;01min\u001b[39;00m car_images:\n\u001b[1;32m     12\u001b[0m     \u001b[38;5;66;03m# Check if the predominant colors match the user's favorite colors\u001b[39;00m\n\u001b[1;32m     13\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mall\u001b[39m(color \u001b[38;5;129;01min\u001b[39;00m favorite_colors \u001b[38;5;28;01mfor\u001b[39;00m color \u001b[38;5;129;01min\u001b[39;00m image[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpredominant_colors\u001b[39m\u001b[38;5;124m\"\u001b[39m]):\n\u001b[1;32m     14\u001b[0m         \u001b[38;5;66;03m# Check if the image orientation matches the user's favorite image orientation\u001b[39;00m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'convert_color_to_rgb' is not defined"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
